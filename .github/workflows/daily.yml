name: Daily NBA Dashboard Refresh

on:
  schedule:
    - cron: "15 8 * * *"   # 12:15 AM PT (08:15 UTC)
    - cron: "0 14 * * *"   # 6:00 AM PT (14:00 UTC)
  workflow_dispatch:
  push:
    paths:
      - "*.py"
      - ".github/workflows/daily.yml"
      - "playerprops/player_whitelist.csv"
      - "players.html"

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: daily-ingest-main
  cancel-in-progress: true

jobs:
  build:
    if: ${{ github.event_name != 'push' || github.actor != 'github-actions[bot]' }}
    runs-on: ubuntu-latest
    env:
      TZ: America/Los_Angeles

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy requests

      # --- Moneyline master ingest ---
      - name: Run ingest script
        run: python espn_daily_ingest.py --out nba_master.csv --max-backfill-days 30

      - name: Validate nba_master.csv
        run: |
          python - <<'PY'
          import pandas as pd, sys

          expected = [
            "game_id","game_date","game_time_utc","home_team_name","home_team_abbrev","home_score","home_ml","home_spread",
            "away_team_name","away_team_abbrev","away_score","away_ml","away_spread","venue_city","venue_state",
            "home_injuries","away_injuries"
          ]

          df = pd.read_csv("nba_master.csv", nrows=1, dtype=str)

          if list(df.columns) != expected:
            print("BAD HEADER:", df.columns.tolist())
            sys.exit(1)

          print("Header OK")
          PY

      - name: Build moneyline postmortem
        run: |
          python build_moneyline_postmortem.py

      # --- Player props ingest (yesterday finals) ---
      - name: Run player props ingest (yesterday)
        run: |
          python espn_player_ingest.py --mode yesterday \
            --whitelist playerprops/player_whitelist.csv \
            --out player_game_log.csv \
            --dim player_dim.csv \
            --sleep 0.25

      - name: Backfill team totals if incomplete
        run: |
          RUN_BACKFILL=$(python - <<'PY'
          import datetime as dt
          import os
          import pandas as pd

          def season_end_year_for_date(d):
              return d.year + 1 if d.month >= 10 else d.year

          master = "nba_master.csv"
          if not os.path.exists(master):
              print(0)
              raise SystemExit(0)
          df = pd.read_csv(master)
          if "game_date" not in df.columns or "game_id" not in df.columns:
              print(0)
              raise SystemExit(0)
          df["game_date"] = pd.to_datetime(df["game_date"], errors="coerce").dt.date
          df = df[df["game_date"].notna()].copy()
          season_end = season_end_year_for_date(dt.date.today())
          df = df[df["game_date"].map(season_end_year_for_date) == season_end].copy()
          df = df[df["home_score"].notna() & df["away_score"].notna()].copy()
          expected = len(df["game_id"].dropna().astype(str).unique()) * 2
          actual = 0
          path = "data/team_game_log.csv"
          if os.path.exists(path):
              try:
                  with open(path, "r", encoding="utf-8") as f:
                      actual = max(0, sum(1 for _ in f) - 1)
              except Exception:
                  actual = 0
          print(1 if actual < expected else 0)
          PY
          )
          if [ "$RUN_BACKFILL" -eq 1 ]; then
            python espn_player_ingest.py --mode backfill_team --master nba_master.csv
          else
            echo "Team totals backfill not needed."
          fi

      - name: Build player snapshot (threshold floors)
        run: |
          python build_player_snapshot_v2.py \
            --in player_game_log.csv \
            --out player_snapshot.csv \
            --master nba_master.csv

      - name: Build targets postmortem
        run: |
          python build_targets_postmortem.py --preset baseline
          python build_targets_postmortem.py --preset expanded

      - name: Debug targets snapshots
        run: |
          echo "=== logs/ ==="
          ls -al logs || true
          echo "=== data/ ==="
          ls -al data || true

      - name: Build performance ledger
        run: |
          python build_perf_daily.py

      - name: Upload unresolved players report
        uses: actions/upload-artifact@v4
        with:
          name: player-unresolved
          path: player_unresolved.csv
          retention-days: 7

      # --- Commit updated CSVs (stateful inputs) ---
      - name: Commit updated CSVs
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git fetch origin main
          git rebase --autostash origin/main

          # Stage the CSVs we expect might change (only if they exist)
          FILES=(
            "nba_master.csv"
            "player_game_log.csv"
            "player_dim.csv"
            "player_snapshot.csv"
            "data/player_snapshot.csv"
            "data/team_opp_allowed.json"
            "data/opp_big.json"
            "data/injuries_today.json"
            "data/player_features.json"
            "data/team_signals.json"
            "data/team_game_log.csv"
            "data/game_times.json"
            "data/moneyline_postmortem.json"
            "data/targets_postmortem.json"
            "logs/injury_log.csv"
          )

          CHANGED=0
          for f in "${FILES[@]}"; do
            if [ -f "$f" ]; then
              if [ -n "$(git status --porcelain -- "$f")" ]; then
                git add "$f"
                CHANGED=1
              fi
            fi
          done

          for f in logs/targets_snapshot_*.json; do
            if [ -f "$f" ]; then
              if [ -n "$(git status --porcelain -- "$f")" ]; then
                git add "$f"
                CHANGED=1
              fi
            fi
          done

          if [ -d "data/history" ]; then
            if [ -n "$(git status --porcelain -- "data/history")" ]; then
              git add data/history
              CHANGED=1
            fi
          fi
          if [ -d "data/perf" ]; then
            if [ -n "$(git status --porcelain -- "data/perf")" ]; then
              git add data/perf
              CHANGED=1
            fi
          fi

          if [ "$CHANGED" -eq 0 ]; then
            echo "No tracked CSV changes; nothing to commit."
            exit 0
          fi

          git status --porcelain

          git commit -m "Daily data refresh [skip ci]" || exit 0

          git push origin HEAD:main

      - name: Upload Rotowire debug HTML
        uses: actions/upload-artifact@v4
        with:
          name: rotowire-debug
          path: debug_rotowire.html
          retention-days: 7

      - name: Build dashboard
        run: |
          python build_matchup_insights.py
          python build_dashboard.py

      - name: Rebuild targets postmortem (sanity)
        run: |
          python build_targets_postmortem.py --preset baseline
          python build_targets_postmortem.py --preset expanded
          echo "===== targets_postmortem.json (head) ====="
          python - <<'PY'
          import json
          p="data/targets_postmortem.json"
          with open(p,"r",encoding="utf-8") as f:
            j=json.load(f)
          print("asof_date:", j.get("asof_date"))
          s=j.get("summary",{}) or {}
          print("targets_total:", s.get("targets_total"), "hits:", s.get("hits_total"), "misses:", s.get("misses_total"))
          PY

      - name: Prepare site files
        run: |
          mkdir -p ./site
          mkdir -p ./site/data
          mkdir -p ./site/assets
          mkdir -p ./site/data/targets_logs

          # Newest dashboard becomes index.html
          export LC_ALL=C
          NEWEST=$(ls dashboard_*.html 2>/dev/null | sort -V | tail -n 1)
          if [ -z "$NEWEST" ]; then
            echo "No dashboard_*.html files found"
            exit 1
          fi
          export NEWEST
          echo "Using newest dashboard: $NEWEST"
          cp "$NEWEST" ./site/index.html
          cp "$NEWEST" "./site/$NEWEST"

          python - <<'PY'
          import json, datetime, os
          newest = os.environ.get("NEWEST")
          meta = {
            "newest_dashboard": newest,
            "built_at_utc": datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z",
          }
          os.makedirs("./site/data", exist_ok=True)
          with open("./site/data/site_meta.json","w",encoding="utf-8") as f:
            json.dump(meta, f, indent=2, sort_keys=True)
          print("Wrote site_meta.json:", meta)
          PY

          # Data files
          cp nba_master.csv ./site/nba_master.csv

          # Branding assets
          cp NBAGPTlogo.png ./site/NBAGPTlogo.png
          cp manifest.webmanifest ./site/manifest.webmanifest
          cp assets/NBAGPTlogo-header.png ./site/assets/NBAGPTlogo-header.png

          # Players page + its data
          cp players.html ./site/players.html
          cp player_snapshot.csv ./site/data/player_snapshot.csv
          cp player_game_log.csv ./site/data/player_game_log.csv
          cp data/injuries_today.json ./site/data/injuries_today.json
          cp data/team_signals.json ./site/data/team_signals.json
          cp data/player_features.json ./site/data/player_features.json
          cp data/game_times.json ./site/data/game_times.json
          cp data/moneyline_postmortem.json ./site/data/moneyline_postmortem.json
          cp data/targets_postmortem.json ./site/data/targets_postmortem.json
          cp data/team_opp_allowed.json ./site/data/team_opp_allowed.json
          cp data/opp_big.json ./site/data/opp_big.json
          if [ -d data/perf ]; then
            cp -R data/perf ./site/data/perf
          fi
          if [ -d data/history ]; then
            cp -R data/history ./site/data/history
          fi
          if ls logs/targets_snapshot_*.json >/dev/null 2>&1; then
            cp logs/targets_snapshot_*.json ./site/data/targets_logs/
          fi

          POST_DATE=$(python - <<'PY'
          import json
          try:
            with open('data/targets_postmortem.json','r',encoding='utf-8') as f:
              print(json.load(f).get('asof_date',''))
          except Exception:
            print('')
          PY
          )
          if [ -z "$POST_DATE" ]; then
            POST_DATE=$(date -u +%F)
          fi
          mkdir -p "./site/data/history/${POST_DATE}"
          for f in \
            data/targets_postmortem.json \
            data/moneyline_postmortem.json \
            data/injuries_today.json \
            data/team_signals.json \
            data/player_features.json \
            data/game_times.json \
            data/team_opp_allowed.json; do
            if [ -f "$f" ]; then
              cp "$f" "./site/data/history/${POST_DATE}/"
            fi
          done
          if [ -f "logs/targets_snapshot_${POST_DATE}.json" ]; then
            cp "logs/targets_snapshot_${POST_DATE}.json" "./site/data/history/${POST_DATE}/targets_snapshot_${POST_DATE}.json"
          else
            echo "Warning: logs/targets_snapshot_${POST_DATE}.json not found"
          fi

          echo "===== SITE DIRECTORY CONTENTS ====="
          ls -al ./site
          echo "===== SITE/DATA DIRECTORY CONTENTS ====="
          ls -al ./site/data

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v4
        with:
          path: ./site

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deploy.outputs.page_url }}

    steps:
      - name: Deploy to GitHub Pages
        id: deploy
        uses: actions/deploy-pages@v4
